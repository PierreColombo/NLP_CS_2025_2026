# Paper Presentation Guidelines

Welcome to the Advanced NLP class for CS students! This section outlines the rules for your paper presentations. Since the presentation accounts for your entire final grade, it is essential to follow these instructions carefully.

## Presentation Duration

**Time limit:** Each presentation should last **10 minutes**. Be concise and focus on the core ideas of your paper while maintaining a clear and pedagogical approach.

## Grading Criteria

Your presentation will be evaluated according to the following criteria:

1. **Clarity & Pedagogy (10 points):** How effectively you explain the concepts and make the material understandable.
2. **Correctness (10 points):** Accuracy and precision in presenting the content of the paper.
3. **Bonus (+2 points):** Awarded for slides that are exceptionally well-designed and enhance comprehension.
4. **Penalty (-1 point):** Applied if you exceed the allocated time.

## What You Should Do

Fill in the [Excel spreadsheet](https://docs.google.com/spreadsheets/d/1PxRQYlLvaOG8e8QKsuLWM5l62XwwEw9lKik3GrinaMQ/edit?gid=0#gid=0) your group members and the paper you have chosen. Each group must consist of **5 members**, and **each paper can be selected by only one group**.

## Paper List

The following papers are available for presentation. Choose one that interests you:

| Category | Title | URL |
|--------|-------|-----|
| Foundations | Attention Is All You Need | https://arxiv.org/abs/1706.03762 |
| Foundations | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | https://arxiv.org/abs/1810.04805 |
| Foundations | GPT-2: Language Models are Unsupervised Multitask Learners | https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf |
| Foundations | Training Compute-Optimal Large Language Models | https://arxiv.org/abs/2203.15556 |
| Data | The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale | https://arxiv.org/abs/2406.17557 |
| Multilingual Models | EuroLLM: Multilingual Language Models for Europe | https://arxiv.org/abs/2409.16235 |
| Multilingual Models | EuroBERT: Scaling Multilingual Encoders for European Languages | https://arxiv.org/abs/2503.05500 |
| Instruction Tuning | Scaling Instruction-Finetuned Language Models | https://arxiv.org/abs/2210.11416 |
| Instruction Tuning | Tower: An Open Multilingual Large Language Model for Translation-Related Tasks | https://arxiv.org/abs/2402.17733 |
| Embeddings | Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks | https://arxiv.org/abs/1908.10084 |
| Embeddings | Dense Passage Retrieval for Open-Domain Question Answering | https://arxiv.org/abs/2004.04906 |
| Embeddings | LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders | https://arxiv.org/abs/2404.05961 |
| Efficiency | LoRA: Low-Rank Adaptation of Large Language Models | https://arxiv.org/abs/2106.09685 |
| Evaluation | BERTScore: Evaluating Text Generation with BERT | https://arxiv.org/abs/1904.09675 |
| Evaluation | COMET: A Neural Framework for MT Evaluation | https://arxiv.org/abs/2009.09025 |
| Evaluation | MTEB: Massive Text Embedding Benchmark| https://arxiv.org/abs/2210.07316 |
| Distillation | Distilling the Knowledge in a Neural Network | https://arxiv.org/abs/1503.02531 |
| Distillation | Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs | https://arxiv.org/abs/2402.12030 |
| Reasoning | s1: Simple test-time scaling | https://arxiv.org/abs/2501.19393 |
| Reasoning | DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning | https://arxiv.org/abs/2501.12948 |
